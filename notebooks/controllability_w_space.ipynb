{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controllability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, \"../../SemanticStyleGAN\")\n",
    "from visualize.utils import generate\n",
    "from utils.control import Control\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt= \"/no_backups/g013/checkpoints/SSG_v3.13/ckpt/140000.pt\"\n",
    "device=\"cpu\"\n",
    "control = Control(ckpt,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent= \"../results/saved_samples/first_latent.npy\"\n",
    "styles = torch.tensor(np.load(latent), device=device)\n",
    "styles = styles.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "\n",
    "\n",
    "latent1= \"../results/saved_samples/first_latent.npy\"\n",
    "latent2= \"../results/saved_samples/second_latent.npy\"\n",
    "latent3= \"../results/saved_samples/third_latent.npy\"\n",
    "latent4=\"../results/saved_samples/fourth_latent.npy\"\n",
    "latent5=\"../results/saved_samples/fifth_latent.npy\"\n",
    "latent6=\"../results/saved_samples/sixth_latent.npy\"\n",
    "latent7=\"../results/saved_samples/seventh_latent.npy\"\n",
    "styles1 = torch.tensor(np.load(latent1), device=device)\n",
    "styles2 = torch.tensor(np.load(latent2), device=device)\n",
    "styles3 = torch.tensor(np.load(latent3), device=device)\n",
    "styles4 = torch.tensor(np.load(latent4), device=device)\n",
    "styles5 = torch.tensor(np.load(latent5), device=device)\n",
    "styles6 = torch.tensor(np.load(latent6), device=device)\n",
    "styles7 = torch.tensor(np.load(latent7), device=device)\n",
    "\n",
    "styles1 = styles1.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles2 = styles2.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles3 = styles3.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles4 = styles4.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles5 = styles5.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles6 = styles6.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles7 = styles7.unsqueeze(1).repeat(1, control.model.n_latent, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions Editing Latent Space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Gradual increase of a certain dimension\n",
    "\n",
    "# #styles_x[0,latent_index,200:400]-=10\n",
    "# old_dist = 0 \n",
    "# class_index = 1##Road\n",
    "# class_index = 2##SideWalk\n",
    "# class_index = 3##Building\n",
    "# class_index = 4##Wall\n",
    "# class_index = 9##Vegitation\n",
    "# class_index = 10##Sky\n",
    "# class_index = 11##Person\n",
    "# # class_index = 13##Car\n",
    "# latent_index=class_index*2+2\n",
    "# images=[]\n",
    "# segs=[]\n",
    "# for i in np.arange(-10,10,0.4):\n",
    "#     image,seg=control.edit_image(latent_index,class_index,change_factor=i*0.1,styles=styles1,addition=True,plot=True)\n",
    "#     images.append(image[0])\n",
    "#     segs.append(seg[0])\n",
    "#     break\n",
    "# #control.images_to_video(images,segs,\"./data/interp_videos/latent_manipulation_person_class.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_2 = torch.nn.functional.interpolate(torch.tensor(images[0]).permute(2,0,1).unsqueeze(0),size=[512,512])\n",
    "# seg_2 = torch.nn.functional.interpolate(torch.tensor(segs[0]).permute(2,0,1).unsqueeze(0),size=[512,512])\n",
    "# print(seg_2.shape)\n",
    "# plt.imshow(np.concatenate((img_2.squeeze(0).permute(1,2,0), seg_2.squeeze(0).permute(1,2,0)), 1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(-10,10,0.4):\n",
    "#     image,seg=control.edit_texture(class_index,change_factor=i*0.1,latent_index=None,styles=styles1,addition=True,plot=True)\n",
    "#     images.append(image[0])\n",
    "#     segs.append(seg[0])\n",
    "#     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying 3 Images (interpolation and FSD calculation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 3 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent1= \"../results/saved_samples/first_latent.npy\"\n",
    "latent2= \"../results/saved_samples/second_latent.npy\"\n",
    "latent3= \"../results/saved_samples/third_latent.npy\"\n",
    "latent4=\"../results/saved_samples/fourth_latent.npy\"\n",
    "latent5=\"../results/saved_samples/fifth_latent.npy\"\n",
    "latent6=\"../results/saved_samples/sixth_latent.npy\"\n",
    "latent7=\"../results/saved_samples/seventh_latent.npy\"\n",
    "styles1 = torch.tensor(np.load(latent1), device=device)\n",
    "styles2 = torch.tensor(np.load(latent2), device=device)\n",
    "styles3 = torch.tensor(np.load(latent3), device=device)\n",
    "styles4 = torch.tensor(np.load(latent4), device=device)\n",
    "styles5 = torch.tensor(np.load(latent5), device=device)\n",
    "styles6 = torch.tensor(np.load(latent6), device=device)\n",
    "styles7 = torch.tensor(np.load(latent7), device=device)\n",
    "\n",
    "styles1 = styles1.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles2 = styles2.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles3 = styles3.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles4 = styles4.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles5 = styles5.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles6 = styles6.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles7 = styles7.unsqueeze(1).repeat(1, control.model.n_latent, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1, seg1 = generate(\n",
    "    control.model,\n",
    "    styles1[0].unsqueeze(0),\n",
    "    mean_latent=control.mean_latent,\n",
    "    randomize_noise=False,\n",
    "    batch_size=control.batch,\n",
    ")\n",
    "image2, seg2 = generate(\n",
    "    control.model,\n",
    "    styles2[0].unsqueeze(0),\n",
    "    mean_latent=control.mean_latent,\n",
    "    randomize_noise=False,\n",
    "    batch_size=control.batch,\n",
    ")\n",
    "image3, seg3 = generate(\n",
    "    control.model,\n",
    "    styles3[0].unsqueeze(0),\n",
    "    mean_latent=control.mean_latent,\n",
    "    randomize_noise=False,\n",
    "    batch_size=control.batch,\n",
    ")\n",
    "## Each image alongside it's class distribution metric\n",
    "mean_val1 = control.get_class_dist(seg1[0])\n",
    "car_percentage1=(mean_val1[0][13]/mean_val1.sum())*100\n",
    "print(car_percentage1)\n",
    "plt.imshow(np.concatenate((image1[0],seg1[0]),1))\n",
    "plt.show()\n",
    "\n",
    "mean_val2 = control.get_class_dist(seg2[0])\n",
    "car_percentage2=(mean_val2[0][13]/mean_val2.sum())*100\n",
    "print(car_percentage2)\n",
    "plt.imshow(np.concatenate((image2[0],seg2[0]),1))\n",
    "plt.show()\n",
    "\n",
    "mean_val3 = control.get_class_dist(seg3[0])\n",
    "car_percentage3=(mean_val3[0][13]/mean_val3.sum())*100\n",
    "print(car_percentage3)\n",
    "plt.imshow(np.concatenate((image3[0],seg3[0]),1))\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) the 3 images used have an increase in probability starting from one to three\n",
    "2) The less the sum of this latent variable the less "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploring the sum of the car latent index\n",
    "latent_index=28\n",
    "latent_name=\"car_shape\"\n",
    "\n",
    "print(f'latent sum for first image is : {styles1[0:latent_index].sum()}, which has car dist of {car_percentage1}')\n",
    "print(f'latent sum for second image is : {styles2[0:latent_index].sum()}, which has car dist of {car_percentage2}')\n",
    "print(f'latent sum for third image is : {styles3[0:latent_index].sum()}, which has car dist of {car_percentage3}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Injecting one image into another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image 1 and 2\n",
    "latent_sum_dist = styles2[0:latent_index].sum() - styles1[0:latent_index].sum()\n",
    "dist_distance=car_percentage2-car_percentage1\n",
    "print(f'Distance between latent vars of image 2 and 1 :{latent_sum_dist}  distance in distribution :{dist_distance}')\n",
    "#Image 2 and 3 \n",
    "latent_sum_dist = styles3[0:latent_index].sum() - styles2[0:latent_index].sum()\n",
    "dist_distance=car_percentage3-car_percentage2\n",
    "print(f'Distance between latent vars of image 3 and 2 :{latent_sum_dist}  distance in distribution :{dist_distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploring what would happen if we feed the shape's latent vector for the car from image 3 to 1\n",
    "styles1_edited = styles1.clone().detach()\n",
    "styles1_edited[0,latent_index] = styles3[0,latent_index]\n",
    "\n",
    "image1_edited, seg1_edited = generate(\n",
    "    model,\n",
    "    styles1_edited[0].unsqueeze(0),\n",
    "    mean_latent=mean_latent,\n",
    "    randomize_noise=False,\n",
    "    batch_size=batch,\n",
    ")\n",
    "\n",
    "latent_sum = styles1_edited[0:latent_index].sum()\n",
    "mean_val1_edited = get_class_dist(seg1_edited[0],color_map)\n",
    "car_percentage1_edited=(mean_val1_edited[0][13]/mean_val1_edited.sum())*100\n",
    "\n",
    "print(f\"Image 1 \")\n",
    "plt.imshow(np.concatenate((image1[0],seg1[0]),1))\n",
    "plt.show()\n",
    "print(f\"Image 3 \")\n",
    "plt.imshow(np.concatenate((image3[0],seg3[0]),1))\n",
    "plt.show()\n",
    "print(f\"Combined Image\")\n",
    "plt.imshow(np.concatenate((image1_edited[0],seg1_edited[0]),1))\n",
    "plt.show()\n",
    "\n",
    "print(f'latent sum after edit is : {latent_sum} and dist_percentage is {car_percentage1_edited}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: You can take the cars of one image and directly inject it into another with generating a plausible image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to find a latent direction for cars using PCA in the W space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal is w0 = w + Vx\n",
    "def calculate_pca_1(model,n_samples=10000,n_components=10):\n",
    "    '''\n",
    "    Calculates PCA and return the V of shape n_components X model.style_dim    \n",
    "    '''\n",
    "    styles = model.style(\n",
    "            torch.randn(n_samples, model.style_dim, device=\"cpu\")\n",
    "        )\n",
    "    pca_res = torch.pca_lowrank(styles,q=n_components)\n",
    "    V = pca_res[2].permute(1,0)\n",
    "    print(f\"Shape of output V from PCA is: {V.shape} \")\n",
    "    return V\n",
    "    \n",
    "def calculate_pca_2(model,n_samples=10000,n_components=10):\n",
    "    styles = model.style(\n",
    "            torch.randn(n_samples, model.style_dim, device=\"cpu\")\n",
    "        )\n",
    "    M = mean(styles)\n",
    "    C = styles-M\n",
    "    V_2=cov(C.T)\n",
    "    _, vectors = eig(V_2) #Returns values and vectors\n",
    "    return vectors[:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V= calculate_pca(model)\n",
    "#torch.save(V,\"principal_components.pt\")\n",
    "\n",
    "#V = torch.load(\"data/principal_components/principal_components.pt\") #output from pytorch\n",
    "V = torch.load(\"data/principal_components/principal_components_2.pt\") #Manual output\n",
    "#V = torch.load(\"data/principal_components/useless_principal_components.pt\") #Useless output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying 10 PC components to image 1 \n",
    "apply_to_all_layers=False\n",
    "latent_index=28 #Car\n",
    "class_index=13\n",
    "\n",
    "# latent_index=20 #Vegitation\n",
    "# class_index=9\n",
    "latent_name=\"car_shape\"\n",
    "multiplier=10\n",
    "\n",
    "for component in range(min(10,V.size(0))):\n",
    "    print(f\"Analyzing COMPONENT {component}\")\n",
    "    control.edit_image_principal_component(latent_index,class_index,multiplier,styles2,V[component])\n",
    "    control.edit_image_principal_component(latent_index,class_index,-multiplier,styles2,V[component])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Effects of continous changing of 1 component\n",
    "apply_to_all_layers=False\n",
    "latent_index=28\n",
    "class_index=13\n",
    "latent_name=\"car_shape\"\n",
    "component=9\n",
    "\n",
    "# chain_1 = range(0,0,1) # Set aside for now \n",
    "# chain_2 =  np.arange(10,-10,-0.1)\n",
    "# mult_range = chain(chain_1,chain_2)\n",
    "\n",
    "for component in [6]:\n",
    "    print(f\"Processing component {component}\")\n",
    "    for i,style_chosen in enumerate([styles1,styles2,styles3,styles4,styles5,styles6,styles7]):\n",
    "        print(f\"Styles{i+1}\")       \n",
    "        images=[]\n",
    "        segs=[]\n",
    "        for multiplier in  np.arange(30,-40,-1):\n",
    "            #print(f\"Analyzing COMPONENT {component} with multiplier {multiplier}\")\n",
    "            image,seg=control.edit_image_principal_component(latent_index,class_index,multiplier,style_chosen,V[component],whole_image=apply_to_all_layers,plot=False,get_image=True)\n",
    "            images.append(image[0])\n",
    "            segs.append(seg[0])\n",
    "        # images = images + images[::-1]\n",
    "        # segs= segs + segs[::-1]\n",
    "       # images_to_video(images,segs,f\"./data/pca_control_2/editing_principal_component_{component}_for_car{i+1}.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combined effect\n",
    "for i,style_chosen in enumerate([styles1,styles2,styles3,styles4,styles5,styles6,styles7]):\n",
    "    print(f\"Styles{i+1}\")       \n",
    "    images=[]\n",
    "    segs=[]\n",
    "    for multiplier in  np.arange(30,-40,-1):\n",
    "        #print(f\"Analyzing COMPONENT {component} with multiplier {multiplier}\")\n",
    "        component_list = [V[1],V[3]]\n",
    "        image,seg=edit_image_principal_component(latent_index,class_index,multiplier,style_chosen,component_list,whole_image=apply_to_all_layers,plot=False,get_image=True)\n",
    "        images.append(image[0])\n",
    "        segs.append(seg[0])\n",
    "\n",
    "    images_to_video(images,segs,f\"./data/pca_control_2/editing_principal_components_1_3_for_car{i+1}.mp4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8daaeadef7a295f68d0e95189507333c5c96e909e217a26b6b4a4818e648299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
