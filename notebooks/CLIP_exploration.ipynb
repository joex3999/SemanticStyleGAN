{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, \"../../SemanticStyleGAN\")\n",
    "from utils.control import Control\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Messing around with clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cpu\"\n",
    "ckpt=\"/no_backups/g013/checkpoints/SSG_v3.13/ckpt/140000.pt\"\n",
    "control = Control(ckpt,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Best 2 models should be either RN50x64, or L/14@336px\n",
    "clip.available_models()\n",
    "model,preprocess=clip.load(\"ViT-B/16\",device=\"cpu\",jit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Seventh does not contain any cars while third contains a lot of cars\n",
    "image_names = [\"first_img\",\"second_img\",\"third_img\",\"fourth_img\",\"fifth_img\",\"sixth_img\",\"seventh_img\"]\n",
    "preprocessed_images=[preprocess(Image.open(f\"../results/saved_samples/{x}.png\")).unsqueeze(0).to(device) for x in image_names]\n",
    "#prompts = [\"Car\",\"cars\", \"a lot of cars\", \"few cars\",\"no cars\",\"road\", \"high number of cars\",\"low number of cars\"]\n",
    "prompts=[\"A street with only one car\",\"A street with a large number of cars \",\"A completely empty street\",\"A street with some trees on the left side\"]\n",
    "text = clip.tokenize(prompts).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=[]\n",
    "\n",
    "## Results with ViT-B/16\n",
    "\n",
    "## Calculating probability\n",
    "with torch.no_grad():\n",
    "    for preprocessed_image in preprocessed_images:\n",
    "     logits_per_image, logits_per_text = model(preprocessed_image, text)\n",
    "     prob = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "     probs.append(prob[0])\n",
    "\n",
    "\n",
    "##Displaying images alongside probability \n",
    "for i,preporcessed_img in enumerate(preprocessed_images):\n",
    "    print(f\"For image {image_names[i]}\")\n",
    "    plt.imshow(preporcessed_img[0].numpy()[0])\n",
    "    plt.show()\n",
    "    prob= probs[i]\n",
    "    acc_string =\"\"\n",
    "    for j,prompt in enumerate(prompts):\n",
    "      acc_string+=f\"{prompt}: {prob[j]:0.2f}%, \"\n",
    "    print(acc_string)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### There are some inconsitencies that I think could be a problem if CLIP in it's current state was used to discover directions for Cityscapes:\n",
    "\n",
    "1. For the prompt \"no cars\": It is expected for image 7 to have the highest prob (RV: 9.6%). while in reality the fourth image with a relatively high car dist has the second highest prob of value : 18%, while the highest prob is 19% for image 1 with 1 car .\n",
    "2. Similar behavior witnessed with the prompt \"low number of cars\" as image 7 or 1 is expected to have a high value(but they got 20% and 15% respectively), but  image 6 had the highest value (46%).\n",
    "3. For \"Car\" prompt: Image 7 with no \"cars\" had a probability of 30% while Image 6 with a lot of cars got the prob of 1%\n",
    "\n",
    "Although on the good side. \n",
    "4. For the prompt \"High number of cars\": Image 6 got the highest probability of 30% compared to Img 7 (9%), Img 1(6.7%) . On average the images of high dist of cars got a higher prob than lower dist images : (Img 6 : 31%, Img3 : 20%, Img2 : 18% VS Img1 : 6.7%, Img7 : 9%) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Best 2 models should be either RN50x64, or L/14@336px\n",
    "clip.available_models()\n",
    "model,preprocess=clip.load(\"ViT-L/14@336px\",device=\"cpu\",jit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Seventh does not contain any cars while third contains a lot of cars\n",
    "image_names = [\"first_img\",\"second_img\",\"third_img\",\"fourth_img\",\"fifth_img\",\"sixth_img\",\"seventh_img\"]\n",
    "preprocessed_images=[preprocess(Image.open(f\"../results/saved_samples/{x}.png\")).unsqueeze(0).to(device) for x in image_names]\n",
    "prompts = [\"Car\",\"cars\", \"a lot of cars\", \"few cars\",\"no cars\",\"high number of cars\", \"low number of cars\"]\n",
    "text = clip.tokenize(prompts).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=[]\n",
    "\n",
    "## Results with ViT-L/14@336px\n",
    "\n",
    "## Calculating probability\n",
    "with torch.no_grad():\n",
    "    for preprocessed_image in preprocessed_images:\n",
    "     logits_per_image, logits_per_text = model(preprocessed_image, text)\n",
    "     prob = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "     probs.append(prob[0])\n",
    "\n",
    "\n",
    "##Displaying images alongside probability \n",
    "for i,preporcessed_img in enumerate(preprocessed_images):\n",
    "    print(f\"For image {image_names[i]}\")\n",
    "    plt.imshow(preporcessed_img[0].numpy()[0])\n",
    "    plt.show()\n",
    "    prob= probs[i]\n",
    "    acc_string =\"\"\n",
    "    for j,prompt in enumerate(prompts):\n",
    "      acc_string+=f\"{prompt}: {prob[j]*100:0.2f}%, \"\n",
    "    print(acc_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings \n",
    "1. For prompt \"high number of cars\" Image 7 with no cars got 6.8% which is a higher number than what image 3 (6.22%) which actually has a high number of cars\n",
    "2. The Image which got the highest number of \"low number of cars\" probability is Image 6 which has the highest amount of cars.\n",
    "3. For the prompt \"Car\" Image 7 got 30% which is higher than image 6, Image 2 got the higher prob of 50% although it has a normal amount of cars compared to other images like 6 and 3 ( which got 33%) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d7fb738a222c2b75f597de638cb4a5050e01a8d2927f5b3984dbaad8d93e00a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
