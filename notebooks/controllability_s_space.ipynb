{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controllability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import numpy as np\n",
    "import imageio\n",
    "from itertools import chain\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, \"../../SemanticStyleGAN\")\n",
    "from models import make_model\n",
    "from visualize.utils import generate, cubic_spline_interpolate\n",
    "from utils.control import Control\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import cov \n",
    "from numpy.linalg import eig\n",
    "from torch import nn\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sefa(model,local_nets,layers,take_conv_weights=True):\n",
    "    '''\n",
    "    Function to get certain weights out of the SSG Model.\n",
    "    local_nets between 0 and 15\n",
    "    layers between 0 and 9\n",
    "    '''\n",
    "    all_local_nets=model.__getattr__(\"local_nets\")\n",
    "    weights = []\n",
    "    if not type(layers)==list:\n",
    "        layers=[layers]\n",
    "    for l_net in local_nets:\n",
    "        for layer in layers:\n",
    "            weight_temp_conv=all_local_nets[l_net].__getattr__(\"linears\")[layer].__getattr__(\"conv\").weight.squeeze(0)\n",
    "            weight_temp_modulation=all_local_nets[l_net].__getattr__(\"linears\")[layer].__getattr__(\"conv\").__getattr__(\"modulation\").weight\n",
    "            weight_temp_conv = weight_temp_conv.flip(2, 3).permute(1, 0, 2, 3).flatten(1)\n",
    "            if take_conv_weights:\n",
    "                 weights.append(weight_temp_conv.cpu().detach().numpy())\n",
    "            else:\n",
    "                 weights.append(weight_temp_modulation.cpu().detach().numpy())\n",
    "    weight = np.concatenate(weights, axis=1).astype(np.float32)\n",
    "    weight = weight / np.linalg.norm(weight, axis=0, keepdims=True)\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(weight.dot(weight.T))\n",
    "\n",
    "    return eigen_vectors.T,eigen_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intialize control and load latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "Initializing model with arguments:\n",
      "{'aug': False,\n",
      " 'base_layers': 2,\n",
      " 'batch': 4,\n",
      " 'channel_multiplier': 2,\n",
      " 'checkpoint_dir': '/no_backups/g013/checkpoints/SSG_v3.13',\n",
      " 'ckpt': None,\n",
      " 'coarse_channel': 512,\n",
      " 'coarse_size': 64,\n",
      " 'd_reg_every': 16,\n",
      " 'dataset': '/no_backups/g013/data/lmdb_datasets/lmdb_v3.3',\n",
      " 'depth_layers': 6,\n",
      " 'detach_texture': False,\n",
      " 'distributed': True,\n",
      " 'g_reg_every': 4,\n",
      " 'inception': '/no_backups/g013/data/inception_models/inception_v3.3.pkl',\n",
      " 'iter': 600001,\n",
      " 'lambda_mask': 100.0,\n",
      " 'latent': 512,\n",
      " 'local_channel': 64,\n",
      " 'local_layers': 10,\n",
      " 'local_rank': 0,\n",
      " 'lr': 0.002,\n",
      " 'min_feat_size': 16,\n",
      " 'mixing': 0.3,\n",
      " 'n_gpu': 4,\n",
      " 'n_mlp': 8,\n",
      " 'n_sample': 16,\n",
      " 'num_workers': 8,\n",
      " 'path_batch_shrink': 2,\n",
      " 'path_regularize': 0.5,\n",
      " 'r1_img': 10,\n",
      " 'r1_seg': 1000,\n",
      " 'residual_refine': True,\n",
      " 'save_every': 5000,\n",
      " 'seg_dim': 16,\n",
      " 'size': 256,\n",
      " 'start_iter': 0,\n",
      " 'transparent_dims': (10, 12),\n",
      " 'viz_every': 2000}\n"
     ]
    }
   ],
   "source": [
    "ckpt=\"/no_backups/g013/checkpoints/SSG_v3.13/ckpt/140000.pt\"\n",
    "device=\"cpu\"\n",
    "control = Control(ckpt,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Styles for Cityscape\n",
    "latent1= \"../results/saved_samples/first_latent.npy\"\n",
    "latent2= \"../results/saved_samples/second_latent.npy\"\n",
    "latent3= \"../results/saved_samples/third_latent.npy\"\n",
    "latent4=\"../results/saved_samples/fourth_latent.npy\"\n",
    "latent5=\"../results/saved_samples/fifth_latent.npy\"\n",
    "latent6=\"../results/saved_samples/sixth_latent.npy\"\n",
    "latent7=\"../results/saved_samples/seventh_latent.npy\"\n",
    "latent_mean=\"../results/saved_samples/mean_latent.npy\"\n",
    "table_2_input = \"../results/saved_samples/table_2_input.npy\"\n",
    "styles1 = torch.tensor(np.load(latent1), device=device)\n",
    "styles2 = torch.tensor(np.load(latent2), device=device)\n",
    "styles3 = torch.tensor(np.load(latent3), device=device)\n",
    "styles4 = torch.tensor(np.load(latent4), device=device)\n",
    "styles5 = torch.tensor(np.load(latent5), device=device)\n",
    "styles6 = torch.tensor(np.load(latent6), device=device)\n",
    "styles7 = torch.tensor(np.load(latent7), device=device)\n",
    "styles_mean = torch.tensor(np.load(latent_mean), device=device)\n",
    "styles_t2= torch.tensor(np.load(table_2_input), device=device)\n",
    "styles1 = styles1.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles2 = styles2.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles3 = styles3.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles4 = styles4.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles5 = styles5.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles6 = styles6.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles7 = styles7.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles_mean = styles_mean.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "styles_t2 = styles_t2.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###Styles for Mapillary\n",
    "# latent1= \"../results/mapillary_picked_samples/000000_latent.npy\"\n",
    "# latent2= \"../results/mapillary_picked_samples/000003_latent.npy\"\n",
    "# latent3= \"../results/mapillary_picked_samples/000004_latent.npy\"\n",
    "# latent4=\"../results/mapillary_picked_samples/000005_latent.npy\"\n",
    "# latent5=\"../results/mapillary_picked_samples/000007_latent.npy\"\n",
    "# latent6=\"../results/mapillary_picked_samples/000009_latent.npy\"\n",
    "# latent7=\"../results/mapillary_picked_samples/000017_latent.npy\"\n",
    "# latent_mean=\"../results/mapillary_picked_samples/mean_latent.npy\"\n",
    "\n",
    "\n",
    "# styles1 = torch.tensor(np.load(latent1), device=device)\n",
    "# styles2 = torch.tensor(np.load(latent2), device=device)\n",
    "# styles3 = torch.tensor(np.load(latent3), device=device)\n",
    "# styles4 = torch.tensor(np.load(latent4), device=device)\n",
    "# styles5 = torch.tensor(np.load(latent5), device=device)\n",
    "# styles6 = torch.tensor(np.load(latent6), device=device)\n",
    "# styles7 = torch.tensor(np.load(latent7), device=device)\n",
    "# styles_mean = torch.tensor(np.load(latent_mean), device=device)\n",
    "\n",
    "# styles1 = styles1.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "# styles2 = styles2.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "# styles3 = styles3.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "# styles4 = styles4.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "# styles5 = styles5.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "# styles6 = styles6.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "# styles7 = styles7.unsqueeze(1).repeat(1, control.model.n_latent, 1)\n",
    "# styles_mean = styles_mean.unsqueeze(1).repeat(1, control.model.n_latent, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get and Save EigenValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m road_index\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m## From 0->9 all layers\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m eigen_vecs,eigen_vals\u001b[39m=\u001b[39mcalculate_sefa(control\u001b[39m.\u001b[39;49mmodel,[road_index],np\u001b[39m.\u001b[39;49marange(\u001b[39m10\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m##From 2->6 shape \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m eigen_vecs_shape,eigen_vals_shape\u001b[39m=\u001b[39mcalculate_sefa(control\u001b[39m.\u001b[39mmodel,[road_index],np\u001b[39m.\u001b[39marange(\u001b[39m2\u001b[39m,\u001b[39m6\u001b[39m))\n",
      "\u001b[1;32m/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb Cell 8\u001b[0m in \u001b[0;36mcalculate_sefa\u001b[0;34m(model, local_nets, layers)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m l_net \u001b[39min\u001b[39;00m local_nets:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m layers:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         weight_temp\u001b[39m=\u001b[39mall_local_nets[l_net]\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mlinears\u001b[39;49m\u001b[39m\"\u001b[39;49m)[layer]\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconv\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         weight_temp \u001b[39m=\u001b[39m weight_temp\u001b[39m.\u001b[39mflip(\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mflatten(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         weights\u001b[39m.\u001b[39mappend(weight_temp\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/usr/stud/faragy/anaconda3/envs/env/lib/python3.9/site-packages/torch/nn/modules/container.py:197\u001b[0m, in \u001b[0;36mModuleList.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mvalues())[idx])\n\u001b[1;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_abs_string_index(idx)]\n",
      "File \u001b[0;32m/usr/stud/faragy/anaconda3/envs/env/lib/python3.9/site-packages/torch/nn/modules/container.py:185\u001b[0m, in \u001b[0;36mModuleList._get_abs_string_index\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_abs_string_index\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m    184\u001b[0m     \u001b[39m\"\"\"Get the absolute index for the list of modules\"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     idx \u001b[39m=\u001b[39m operator\u001b[39m.\u001b[39;49mindex(idx)\n\u001b[1;32m    186\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m idx \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)):\n\u001b[1;32m    187\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mindex \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is out of range\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "car_index=13\n",
    "tree_index=9\n",
    "road_index=1\n",
    "## From 0->9 all layers\n",
    "eigen_vecs,eigen_vals=calculate_sefa(control.model,[road_index],np.arange(10))\n",
    "##From 2->6 shape \n",
    "eigen_vecs_shape,eigen_vals_shape=calculate_sefa(control.model,[road_index],np.arange(2,6))\n",
    "##From 6->10 Texture \n",
    "eigen_vecs_texture,eigen_vals_texture=calculate_sefa(control.model,[road_index],np.arange(6,10))\n",
    "\n",
    "## Expanding the tensor from 64x64 to 64x512\n",
    "# eigen_vecs = torch.repeat_interleave(torch.tensor(eigen_vecs),8,dim=1).numpy()\n",
    "# eigen_vecs_shape = torch.repeat_interleave(torch.tensor(eigen_vecs_shape),8,dim=1).numpy()\n",
    "# eigen_vecs_texture = torch.repeat_interleave(torch.tensor(eigen_vecs_texture),8,dim=1).numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Editing Images using GAN-Space in W Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing component 4\n",
      "Styles1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m segs\u001b[39m=\u001b[39m[]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m multiplier \u001b[39min\u001b[39;00m  np\u001b[39m.\u001b[39mlinspace(\u001b[39m60\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m60\u001b[39m,\u001b[39m40\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m#print(f\"Analyzing COMPONENT {component} with multiplier {multiplier}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m#image,seg=control.edit_image_inject_coarse(class_index,multiplier,style_chosen,V[component],coarse_inject_layer=coarse_layer,plot=False,get_image=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m#latent_index = np.arange(5, 34, 2) ##For Editing all textures at once.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     image,seg\u001b[39m=\u001b[39mcontrol\u001b[39m.\u001b[39;49medit_image_principal_component(latent_index,class_index,multiplier,style_chosen,V[component],whole_image\u001b[39m=\u001b[39;49mapply_to_all_layers,plot\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,get_image\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     images\u001b[39m.\u001b[39mappend(image[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     segs\u001b[39m.\u001b[39mappend(seg[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/storage/user/faragy/SemanticStyleGAN/utils/control.py:305\u001b[0m, in \u001b[0;36mControl.edit_image_principal_component\u001b[0;34m(self, latent_index, class_index, change_factor, styles, principal_component, whole_image, plot, get_image)\u001b[0m\n\u001b[1;32m    299\u001b[0m     principal_component \u001b[39m=\u001b[39m (\n\u001b[1;32m    300\u001b[0m         principal_component\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    301\u001b[0m         \u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    302\u001b[0m         \u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mn_latent, \u001b[39m1\u001b[39m)\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m     styles_copy \u001b[39m=\u001b[39m styles_copy \u001b[39m+\u001b[39m (principal_component\u001b[39m.\u001b[39mfloat() \u001b[39m*\u001b[39m change_factor)\n\u001b[0;32m--> 305\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_and_plot_image(\n\u001b[1;32m    306\u001b[0m     styles_copy, class_index, plot\u001b[39m=\u001b[39;49mplot, get_image\u001b[39m=\u001b[39;49mget_image\n\u001b[1;32m    307\u001b[0m )\n",
      "File \u001b[0;32m/storage/user/faragy/SemanticStyleGAN/utils/control.py:137\u001b[0m, in \u001b[0;36mControl.generate_and_plot_image\u001b[0;34m(self, styles, class_index, coords, plot, get_image, mask)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_and_plot_image\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[39mself\u001b[39m, styles, class_index, coords\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, get_image\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    136\u001b[0m ):\n\u001b[0;32m--> 137\u001b[0m     image, seg \u001b[39m=\u001b[39m generate(\n\u001b[1;32m    138\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    139\u001b[0m         styles[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m),\n\u001b[1;32m    140\u001b[0m         mean_latent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean_latent,\n\u001b[1;32m    141\u001b[0m         randomize_noise\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    142\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch,\n\u001b[1;32m    143\u001b[0m         coords\u001b[39m=\u001b[39;49mcoords,\n\u001b[1;32m    144\u001b[0m         composition_mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    147\u001b[0m     all_classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_class_dist(seg[\u001b[39m0\u001b[39m], color_map)\n\u001b[1;32m    148\u001b[0m     class_percentage \u001b[39m=\u001b[39m (all_classes[\u001b[39m0\u001b[39m][class_index] \u001b[39m/\u001b[39m all_classes\u001b[39m.\u001b[39msum()) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n",
      "File \u001b[0;32m/storage/user/faragy/SemanticStyleGAN/visualize/utils.py:84\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(model, styles, mean_latent, truncation, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     segs\u001b[39m.\u001b[39mappend(segs_\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m     83\u001b[0m images, segs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(images, \u001b[39m0\u001b[39m), torch\u001b[39m.\u001b[39mcat(segs, \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m \u001b[39mreturn\u001b[39;00m tensor2image(images), tensor2seg(segs)\n",
      "File \u001b[0;32m/storage/user/faragy/SemanticStyleGAN/visualize/utils.py:121\u001b[0m, in \u001b[0;36mtensor2seg\u001b[0;34m(sample_seg)\u001b[0m\n\u001b[1;32m    116\u001b[0m sample_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\n\u001b[1;32m    117\u001b[0m     (sample_seg\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], sample_seg\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], sample_seg\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], \u001b[39m3\u001b[39m),\n\u001b[1;32m    118\u001b[0m     dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8,\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(seg_dim):\n\u001b[0;32m--> 121\u001b[0m     sample_mask[sample_seg \u001b[39m==\u001b[39m key] \u001b[39m=\u001b[39m color_map[key]\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m sample_mask\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Effects of continous changing of 1 component\n",
    "\n",
    "apply_to_all_layers=False\n",
    "class_index=9\n",
    "latent_index = 28\n",
    "latent_name=\"car_shape\"\n",
    "component=9\n",
    "coarse_layer=1\n",
    "# chain_1 = range(0,0,1) # Set aside for now \n",
    "# chain_2 =  np.arange(10,-10,-0.1)\n",
    "# mult_range = chain(chain_1,chain_2)\n",
    "#V=eigen_vecs_shape\n",
    "V=torch.load(\"../results/mapillary_picked_samples/principal_components_2_mapillary.pt\")\n",
    "\"trees/cars/road/building\"\n",
    "classes= [\"vegi_texture\"]\n",
    "latent_indices=[21,29,5,9]\n",
    "for class_name,latent_index in zip (classes,latent_indices):\n",
    "    for component in [4]:\n",
    "        print(f\"Processing component {component}\")\n",
    "        #[styles_mean,styles1,styles3]\n",
    "        for i,style_chosen in enumerate([styles1,styles2,styles3,styles4,styles5,styles6,styles7,styles_mean]):\n",
    "            print(f\"Styles{i+1}\")    \n",
    "            images=[]\n",
    "            segs=[]\n",
    "            for multiplier in  np.linspace(60,-60,40):\n",
    "                #print(f\"Analyzing COMPONENT {component} with multiplier {multiplier}\")\n",
    "                #image,seg=control.edit_image_inject_coarse(class_index,multiplier,style_chosen,V[component],coarse_inject_layer=coarse_layer,plot=False,get_image=True)\n",
    "                #latent_index = np.arange(5, 34, 2) ##For Editing all textures at once.\n",
    "                image,seg=control.edit_image_principal_component(latent_index,class_index,multiplier,style_chosen,V[component],whole_image=apply_to_all_layers,plot=False,get_image=True)\n",
    "                images.append(image[0])\n",
    "                segs.append(seg[0])\n",
    "            # images = images + images[::-1]\n",
    "            # segs= segs + segs[::-1]\n",
    "            control.images_to_video(images,segs,f\"./data/thesis_results_mapillary/W_space_class_name_{class_name}{component}_for_image_{i+1}.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of a mean Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creation of a mean image to easily see the effect of one S space direction.\n",
    "styles = control.model.style(\n",
    "        torch.randn(50000, control.model.style_dim, device=\"cpu\")\n",
    "    )\n",
    "\n",
    "mean_style=styles.mean(0).unsqueeze(0)\n",
    "np.save(\"../results/mapillary_picked_samples/mean_latent.npy\",mean_style.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of applying S space directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_w_to_w_extended(model,w_vectors,local_generator,layer):\n",
    "    '''\n",
    "    A function that converts given w_vectors of size Nx512 to Nx64 given a specific demodulation in the model.\n",
    "    '''\n",
    "    modulation=control.model.__getattr__(\"local_nets\")[local_generator].__getattr__(\"linears\")[layer].__getattr__(\"conv\").modulation\n",
    "    return modulation(w_vectors)\n",
    "    \n",
    "def prepare_w_extended(model,style,w_extended,class_index,layers):\n",
    "    assert len(style.shape)==1\n",
    "    for layer_index in layers:\n",
    "         w_extended[class_index][layer_index]=convert_from_w_to_w_extended(model,style,class_index,layer_index).detach()\n",
    "    return w_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pca_2(samples,selected=10):\n",
    "    samples_cop = samples.cpu().detach().numpy()\n",
    "    M = mean(samples_cop)\n",
    "    C = samples_cop-M\n",
    "    V_2=cov(C.T)\n",
    "    values, vectors = eig(V_2)\n",
    "    return values[:selected],vectors[:selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pca_from_s_space(model,local_generator,layer):\n",
    "    styles =model.style(\n",
    "        torch.randn(50000, model.style_dim, device=\"cpu\")\n",
    "    )\n",
    "    styles_converted=convert_from_w_to_w_extended(control.model,styles,local_generator,layer)\n",
    "    _,vectors = calculate_pca_2(styles_converted,selected=513)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv=calculate_pca_from_s_space(control.model,13,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'control' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m truncation_mean \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m truncation\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m mean_latent \u001b[39m=\u001b[39mcontrol\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mstyle(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     torch\u001b[39m.\u001b[39mrandn(truncation_mean, control\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mstyle_dim, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\u001b[39m.\u001b[39mmean(\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m styles \u001b[39m=\u001b[39m control\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mstyle(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         torch\u001b[39m.\u001b[39mrandn(\u001b[39m50000\u001b[39m, control\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mstyle_dim, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m##Truncation 50k styles.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#styles = truncation * styles + (1 - truncation) * mean_latent.unsqueeze(0)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'control' is not defined"
     ]
    }
   ],
   "source": [
    "##Extraction of PCA directions from the converted w extended space\n",
    "truncation_mean = 10000\n",
    "truncation=0.7\n",
    "mean_latent =control.model.style(\n",
    "    torch.randn(truncation_mean, control.model.style_dim, device=\"cpu\")\n",
    ").mean(0)\n",
    "\n",
    "styles = control.model.style(\n",
    "        torch.randn(50000, control.model.style_dim, device=\"cpu\")\n",
    "    )\n",
    "##Truncation 50k styles.\n",
    "#styles = truncation * styles + (1 - truncation) * mean_latent.unsqueeze(0)\n",
    "local_generator=13\n",
    "layer=5\n",
    "styles_converted=convert_from_w_to_w_extended(control.model,styles,local_generator,layer)\n",
    "res_2 = calculate_pca_2(styles_converted,selected=513)\n",
    "vectors = res_2[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m latent_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcar_shape\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m w_extended\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mzeros(\u001b[39m16\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m64\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m V,_\u001b[39m=\u001b[39mcalculate_sefa(control\u001b[39m.\u001b[39;49mmodel,[class_index],layer_index)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m component \u001b[39min\u001b[39;00m [\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m9\u001b[39m,\u001b[39m10\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing component \u001b[39m\u001b[39m{\u001b[39;00mcomponent\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb Cell 27\u001b[0m in \u001b[0;36mcalculate_sefa\u001b[0;34m(model, local_nets, layers, take_conv_weights)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m l_net \u001b[39min\u001b[39;00m local_nets:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m layers:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         weight_temp_conv\u001b[39m=\u001b[39mall_local_nets[l_net]\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mlinears\u001b[39;49m\u001b[39m\"\u001b[39;49m)[layer]\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconv\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         weight_temp_modulation\u001b[39m=\u001b[39mall_local_nets[l_net]\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlinears\u001b[39m\u001b[39m\"\u001b[39m)[layer]\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconv\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodulation\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mweight\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Batcremers58.in.tum.de/usr/stud/faragy/storage/user/SemanticStyleGAN/notebooks/controllability_sefa.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         weight_temp_conv \u001b[39m=\u001b[39m weight_temp_conv\u001b[39m.\u001b[39mflip(\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mflatten(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/stud/faragy/anaconda3/envs/env/lib/python3.9/site-packages/torch/nn/modules/container.py:197\u001b[0m, in \u001b[0;36mModuleList.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mvalues())[idx])\n\u001b[1;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_abs_string_index(idx)]\n",
      "File \u001b[0;32m/usr/stud/faragy/anaconda3/envs/env/lib/python3.9/site-packages/torch/nn/modules/container.py:185\u001b[0m, in \u001b[0;36mModuleList._get_abs_string_index\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_abs_string_index\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m    184\u001b[0m     \u001b[39m\"\"\"Get the absolute index for the list of modules\"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     idx \u001b[39m=\u001b[39m operator\u001b[39m.\u001b[39;49mindex(idx)\n\u001b[1;32m    186\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m idx \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)):\n\u001b[1;32m    187\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mindex \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is out of range\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "## Effects of continous changing of 1 component\n",
    "\n",
    "apply_to_all_layers=False\n",
    "latent_index=4\n",
    "class_index=13\n",
    "layer_index=5\n",
    "layer_index=np.arange(2,6)\n",
    "latent_name=\"car_shape\"\n",
    "w_extended=torch.zeros(16,10,64)\n",
    "\n",
    "V,_=calculate_sefa(control.model,[class_index],layer_index)\n",
    "for component in [6,7,8,9,10]:\n",
    "    print(f\"Processing component {component}\")\n",
    "    for i,style_chosen in enumerate([styles_mean,styles1,styles2,styles3,styles5]):\n",
    "        print(f\"Styles{i+1}\")    \n",
    "        images=[]\n",
    "        segs=[]\n",
    "        for multiplier in  np.linspace(-30,30,35):\n",
    "            w_extended_copy = w_extended.clone().detach()\n",
    "            w_extended_copy=prepare_w_extended(control.model,style_chosen[0][0],w_extended_copy,class_index,layer_index)\n",
    "            w_extended_copy[class_index][layer_index]+=(multiplier*V[component])\n",
    "            #print(f\"Analyzing COMPONENT {component} with multiplier {multiplier}\")\n",
    "            image,seg= control.edit_image_inject_modulation(class_index,style_chosen,w_extended_copy,plot=False,get_image=True)\n",
    "            images.append(image[0])\n",
    "            segs.append(seg[0])\n",
    "\n",
    "        control.images_to_video(images,segs,f\"./data/64_v/shape_layers_sefa/for_image_{i+1}_component_{component}_class_{class_index}_layer_{layer_index}.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Further why sefa is not producing good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training and testing cell for both sefa and PCa on S space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class_index : 13  layer index: [5] with components [1, 2]\n",
      "Found numpy file with the same exact directions, loading  ...\n",
      "Processing component 1\n",
      "Styles1\n",
      "Processing component 2\n",
      "Styles1\n",
      "Processing class_index : 13  layer index: [4] with components [1, 2]\n",
      "Found numpy file with the same exact directions, loading  ...\n",
      "Processing component 1\n",
      "Styles1\n",
      "Processing component 2\n",
      "Styles1\n"
     ]
    }
   ],
   "source": [
    "## Effects of continous changing of 1 component\n",
    "apply_to_all_layers=False\n",
    "latent_index=4\n",
    "class_index = 1 #Road\n",
    "class_index = 13 #Car\n",
    "class_index = 9 #Vegi.\n",
    "class_index = 10 #Sky\n",
    "component=9\n",
    "coarse_layer=1\n",
    "w_extended=torch.zeros(16,10,64)\n",
    "shape_layers=[2,3,4,5]\n",
    "texture_layers=[6,7,8,9]\n",
    "#Training list of format :\n",
    "'''\n",
    "[ [Class_index,LocalGeneratorLayer, [V_components]] , ...another training param..]\n",
    "'''\n",
    "\n",
    "top_10_dir=[0,1,2,3,4,5,6,7,8,9]\n",
    "training_list = [[10,[5],top_10_dir],\n",
    "[10,[4],top_10_dir],\n",
    "[10,[3],top_10_dir],\n",
    "[10,[9],top_10_dir],\n",
    "[10,[8],top_10_dir],\n",
    "[10,[7],top_10_dir],]\n",
    "training_list=[[13,[5],[1,2]],\n",
    "                [13,[4],[1,2]]]\n",
    "#Training List After\n",
    "# training_list = [[13,[5],[9,10,11,12]],\n",
    "#                 [13,[4],[9,10,11,12]],\n",
    "#                 [13,[4,5],[0,1,2,3,4,5,6]],\n",
    "# ]            \n",
    "#training_list = [[13,[6,7,8,9],[0,1,2,3,4,5,6,7,8]]]\n",
    "\n",
    "#Mapillary related results.\n",
    "vegi_focused_styles_mp=[styles1,styles5,styles_mean]\n",
    "sky_focused_styles_mp=[styles3,styles5]\n",
    "car_focuses_styles_mp=[styles6,styles7]\n",
    "#CityScapes related res\n",
    "vegi_focused_styles_cs=[styles1,styles4,styles7]\n",
    "\n",
    "styles_list=[styles_mean]\n",
    "saved_pcas=[]\n",
    "#V=calculate_pca_from_s_space(control.model,class_index,layer_index)\n",
    "for training_instance in training_list:\n",
    "    class_index = training_instance[0]\n",
    "    layer_index= training_instance[1]\n",
    "    components = training_instance[2]\n",
    "    print(f\"Processing class_index : {class_index}  layer index: {layer_index} with components {components}\")\n",
    "    #Notice that currently we are calculating weights from modulated part of the layer instead of main conv layer.\n",
    "    \n",
    "    \n",
    "    #V,_=calculate_sefa(control.model,[class_index],layer_index,take_conv_weights=True)\n",
    "    #V=calculate_pca_from_s_space(control.model,class_index,layer_index[0])\n",
    "    #saved_pcas.append(V)\n",
    "\n",
    "    save_path=f\"./thesis_related_results/saved_numpy/layer_{layer_index[0]}_class_index_{class_index}.npy\"\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        np.save(save_path,V)\n",
    "    else:\n",
    "        print(f\"Found numpy file with the same exact directions, loading  ...\")\n",
    "        V = np.load(save_path)\n",
    "        #raise Exception(\"File already exists, you sure you want to overwrite ?\")\n",
    "    #V_2 = np.load(f\"./data/mapillary/s_space/layer_{4}_class_index_{class_index}.npy\")\n",
    "    for component in components:\n",
    "        print(f\"Processing component {component}\")\n",
    "        for i,style_chosen in enumerate(styles_list):\n",
    "            print(f\"Styles{i+1}\")    \n",
    "            images=[]\n",
    "            segs=[]\n",
    "            for multiplier in  np.linspace(-70,70,18):\n",
    "                w_extended_copy = w_extended.clone().detach()\n",
    "                w_extended_copy=prepare_w_extended(control.model,style_chosen[0][0],w_extended_copy,class_index,layer_index)\n",
    "                w_extended_copy[class_index][layer_index[0]]+=((multiplier)*V[component])\n",
    "                #w_extended_copy[class_index][4]+=((multiplier)*V_2[1])\n",
    "                ##For Double EFFECT !!!! Remove !!!\n",
    "                #print(f\"Analyzing COMPONENT {component} with multiplier {multiplier}\")\n",
    "                image,seg= control.edit_image_inject_modulation(class_index,style_chosen,w_extended_copy,plot=False,get_image=True)\n",
    "                images.append(image[0])\n",
    "                segs.append(seg[0])\n",
    "            control.images_to_video(images,segs,f\"./thesis_related_results/table_2/retake/s_gan_space_layer_{layer_index}_{component}_component_for_image_{i+1}__class_{class_index}_xxxx.mp4\")\n",
    "            #control.images_to_video(images,segs,f\"./data/mapillary/s_space/class_index={class_index}/layer_{layer_index}_component_{component}_for_image_{i+1}__class_{class_index}.mp4\")\n",
    "            #control.images_to_video(images,segs,f\"./thesis_related_results/s_space/class_index={class_index}/layer_{layer_index}_{component}_component_for_image_{i+1}__class_{class_index}.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d7fb738a222c2b75f597de638cb4a5050e01a8d2927f5b3984dbaad8d93e00a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
